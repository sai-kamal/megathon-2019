{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('./arxivData.json')\n",
    "data = data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [\"I love machine learning. Its awesome.\",\n",
    "#         \"I love coding in python\",\n",
    "#         \"I love building chatbots\",\n",
    "#         \"they chat amagingly well\"]\n",
    "\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(data1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kamal/.local/lib/python3.6/site-packages/gensim/models/doc2vec.py:574: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kamal/.local/lib/python3.6/site-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 20\n",
      "iteration 21\n",
      "iteration 22\n",
      "iteration 23\n",
      "iteration 24\n",
      "iteration 25\n",
      "iteration 26\n",
      "iteration 27\n",
      "iteration 28\n",
      "iteration 29\n",
      "iteration 30\n",
      "iteration 31\n",
      "iteration 32\n",
      "iteration 33\n",
      "iteration 34\n",
      "iteration 35\n",
      "iteration 36\n",
      "iteration 37\n",
      "iteration 38\n",
      "iteration 39\n",
      "iteration 40\n",
      "iteration 41\n",
      "iteration 42\n",
      "iteration 43\n",
      "iteration 44\n",
      "iteration 45\n",
      "iteration 46\n",
      "iteration 47\n",
      "iteration 48\n",
      "iteration 49\n",
      "iteration 50\n",
      "iteration 51\n",
      "iteration 52\n",
      "iteration 53\n",
      "iteration 54\n",
      "iteration 55\n",
      "iteration 56\n",
      "iteration 57\n",
      "iteration 58\n",
      "iteration 59\n",
      "iteration 60\n",
      "iteration 61\n",
      "iteration 62\n",
      "iteration 63\n",
      "iteration 64\n",
      "iteration 65\n",
      "iteration 66\n",
      "iteration 67\n",
      "iteration 68\n",
      "iteration 69\n",
      "iteration 70\n",
      "iteration 71\n",
      "iteration 72\n",
      "iteration 73\n",
      "iteration 74\n",
      "iteration 75\n",
      "iteration 76\n",
      "iteration 77\n",
      "iteration 78\n",
      "iteration 79\n",
      "iteration 80\n",
      "iteration 81\n",
      "iteration 82\n",
      "iteration 83\n",
      "iteration 84\n",
      "iteration 85\n",
      "iteration 86\n",
      "iteration 87\n",
      "iteration 88\n",
      "iteration 89\n",
      "iteration 90\n",
      "iteration 91\n",
      "iteration 92\n",
      "iteration 93\n",
      "iteration 94\n",
      "iteration 95\n",
      "iteration 96\n",
      "iteration 97\n",
      "iteration 98\n",
      "iteration 99\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 100\n",
    "vec_size = 20\n",
    "alpha = 0.025\n",
    "\n",
    "model = Doc2Vec(size=vec_size,\n",
    "                alpha=alpha, \n",
    "                min_alpha=0.00025,\n",
    "                min_count=1,\n",
    "                dm =1)\n",
    "  \n",
    "model.build_vocab(tagged_data)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print('iteration {0}'.format(epoch))\n",
    "    model.train(tagged_data,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.iter)\n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha\n",
    "\n",
    "model.save(\"d2v.model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('45', 0.7440826892852783), ('40', 0.7256994247436523), ('18', 0.7026613354682922), ('34', 0.6826136708259583), ('75', 0.6548233032226562), ('8', 0.6488504409790039), ('24', 0.6273770332336426), ('10', 0.6230689883232117), ('47', 0.6211402416229248), ('46', 0.6071608662605286)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "model= Doc2Vec.load(\"d2v.model\")\n",
    "#to find the vector of a document which is not in training data\n",
    "test_data = word_tokenize(\"We propose an architecture for VQA which utilizes recurrent layers to\\ngenerate visual and textual attention. The memory characteristic of the\\nproposed recurrent attention units offers a rich joint embedding of visual and\\ntextual features and enables the model to reason relations between several\\nparts of the image and question. Our single model outperforms the first place\\nwinner on the VQA 1.0 dataset, performs within margin to the current\\nstate-of-the-art ensemble model. We also experiment with replacing attention\\nmechanisms in other state-of-the-art models with our implementation and show\\nincreased accuracy. In both cases, our recurrent attention mechanism improves\\nperformance in tasks requiring sequential or relational reasoning on the VQA\\ndataset.\".lower())\n",
    "v1 = model.infer_vector(test_data)\n",
    "# print(\"V1_infer\", v1)\n",
    "\n",
    "# to find most similar doc using tags\n",
    "similar_doc = model.docvecs.most_similar('1')\n",
    "print(similar_doc)\n",
    "# print(model.docvecs['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\"\"]*11\n",
    "a[0] = '''We propose a novel application of Formal Concept Analysis (FCA) to neural decoding: instead of just trying to figure out which stimulus was presented, we demonstrate how to explore the semantic relationships between the neural representation of large sets of stimuli. FCA provides a way of displaying and interpreting such relationships via concept lattices. We explore the effects of neural code sparsity on the lattice. We then analyze neurophysiological data from high-level visual cortical area STSa, using an exact Bayesian approach to construct the formal context needed by FCA. Prominent features of the resulting concept lattices are discussed, including indications for a product-of-experts code in real neurons.'''\n",
    "a[1] = '''Finding relevant publications is important for scientists who have to cope with exponentially increasing numbers of scholarly material. Algorithms can help with this task as they help for music, movie, and product recommendations. However, we know little about the performance of these algorithms with scholarly material. Here, we develop an algorithm, and an accompanying Python library, that implements a recommendation system based on the content of articles. Design principles are to adapt to new content, provide near-real time suggestions, and be open source. We tested the library on 15K posters from the Society of Neuroscience Conference 2015. Human curated topics are used to cross validate parameters in the algorithm and produce a similarity metric that maximally correlates with human judgments. We show that our algorithm significantly outperformed suggestions based on keywords. The work presented here promises to make the exploration of scholarly material faster and more accurate.'''\n",
    "a[2] = '''Dynamic programming is a powerful method for solving combinatorial optimization problems. However, it does not always work well, particularly for some NP-hard problems\n",
    "having extremely large state spaces. In this paper, we propose an approach to boost the\n",
    "capability of dynamic programming with neural networks. First, we replace the conventional tabular method with neural networks of polynomial sizes to approximately represent\n",
    "dynamic programming functions. And then we design an iterative algorithm to train the\n",
    "neural network with data generated from a solution reconstruction process. Our method\n",
    "combines the approximating ability and flexibility of neural networks and the advantage\n",
    "of dynamic programming in utilizing intrinsic properties of a problem. This approach can\n",
    "significantly reduce the space complexity and it is flexible in balancing space, running time,\n",
    "and accuracy. We apply the method to the Travelling Salesman Problem (TSP). The experimental results show that our approach can solve larger problems that are intractable for\n",
    "conventional dynamic programming and the performances are near optimal, outperforming\n",
    "the well-known approximation algorithms'''\n",
    "a[3] = '''We explore a model-based approach to reinforcement learning where partially or totally unknown dynamics are learned and explicit planning is performed. We learn dynamics with neural networks, and plan behaviors with differential dynamic programming (DDP). In order to handle complicated dynamics, such as manipulating liquids (pouring), we consider temporally decomposed dynamics. We start from our recent work [1] where we used locally weighted regression (LWR) to model dynamics. The major contribution of this paper is making use of deep learning in the form of neural networks with stochastic DDP, and showing the advantages of neural networks over LWR. For this purpose, we extend neural networks for: (1) modeling prediction error and output noise, (2) computing an output probability distribution for a given input distribution, and (3) computing gradients of output expectation with respect to an input. Since neural networks have nonlinear activation functions, these extensions were not easy. We provide an analytic solution for these extensions using some simplifying assumptions. We verified this method in pouring simulation experiments. The learning performance with neural networks was better than that of LWR. The amount of spilled materials was reduced. We also present early results of robot experiments using a PR2. '''\n",
    "a[4] = '''With the increasing number of scienti\u001bc publications, research\n",
    "paper recommendation has become increasingly important for scientists. Most researchers rely on keyword-based search or following\n",
    "citations in other papers, in order to \u001bnd relevant research articles.\n",
    "And usually they spend a lot of time without getting satisfactory\n",
    "results. This study aims to propose a personalized research paper\n",
    "recommendation system, that facilitate this task by recommending\n",
    "papers based on users’ explicit and implicit feedback. The users will\n",
    "be allowed to explicitly specify the papers of interest. In addition,\n",
    "user activities (e.g., viewing abstracts or full-texts) will be analyzed\n",
    "in order to enhance users’ pro\u001bles. Most of the current research\n",
    "paper recommendation and information retrieval systems use the\n",
    "classical bag-of-words methods, which don’t consider the context\n",
    "of the words and the semantic similarity between the articles. This\n",
    "study will use Recurrent Neural Networks (RNNs) to discover continuous and latent semantic features of the papers, in order to\n",
    "improve the recommendation quality. The proposed approach utilizes PubMed so far, since it is frequently used by physicians and\n",
    "scientists, but it can easily incorporate other datasets in the future.'''\n",
    "a[5] = '''We address the problem of hate speech detection in online\n",
    "user comments. Hate speech, defined as an \\abusive speech\n",
    "targeting specific group characteristics, such as ethnicity, religion, or gender\", is an important problem plaguing websites\n",
    "that allow users to leave feedback, having a negative impact\n",
    "on their online business and overall user experience. We propose to learn distributed low-dimensional representations of\n",
    "comments using recently proposed neural language models,\n",
    "that can then be fed as inputs to a classification algorithm.\n",
    "Our approach addresses issues of high-dimensionality and\n",
    "sparsity that impact the current state-of-the-art, resulting\n",
    "in highly efficient and effective hate speech detectors'''\n",
    "a[6] = '''A key challenge for automatic hate-speech detection on social media is the separation of hate speech from other instances of offensive language. Lexical detection methods tend\n",
    "to have low precision because they classify all messages containing particular terms as hate speech and previous work using supervised learning has failed to distinguish between the\n",
    "two categories. We used a crowd-sourced hate speech lexicon\n",
    "to collect tweets containing hate speech keywords. We use\n",
    "crowd-sourcing to label a sample of these tweets into three\n",
    "categories: those containing hate speech, only offensive language, and those with neither. We train a multi-class classifier to distinguish between these different categories. Close\n",
    "analysis of the predictions and the errors shows when we can\n",
    "reliably separate hate speech from other offensive language\n",
    "and when this differentiation is more difficult. We find that\n",
    "racist and homophobic tweets are more likely to be classified\n",
    "as hate speech but that sexist tweets are generally classified\n",
    "as offensive. Tweets without explicit hate keywords are also\n",
    "more difficult to classify'''\n",
    "a[7] = '''This paper describes a system to extract aspect categories for the task of aspect based sentiment\n",
    "analysis. This system can extract both implicit and explicit aspects. We propose a one-vs-rest\n",
    "Support Vector Machine (SVM) classifier preceded by a state of the art preprocessing pipeline.\n",
    "We present the use of mean embeddings as a feature along with two other new features to\n",
    "significantly improve the accuracy of the SVM classifier. This solution is extensible to\n",
    "customer reviews in different domains. '''\n",
    "\n",
    "a[8] = '''The prediction of drought is of major importance\n",
    "in climate-related studies, hydrologic engineering, wildlife or\n",
    "agricultural studies. This study explores the ability of two\n",
    "machine learning methods to predict 1, 3, 6 and 12 months\n",
    "standardized precipitation and evapotranspiration index (SPEI)\n",
    "for the Wilsons Promontory station in Eastern Australia. The two\n",
    "methods are multiple linear regression (MLR) and artificial\n",
    "neural networks (ANN). The data-driven models were based on\n",
    "combinations of the input variables: mean precipitations, mean,\n",
    "maximum and minimum temperatures and evapotranspiration,\n",
    "for data between 1915 and 2012. Two performance metrics were\n",
    "used to compare the performance of the optimum MLR and ANN\n",
    "models: the coefficient of determination (R2) and the root mean\n",
    "square error (RMSE). It was found that ANN provided greater\n",
    "accuracy than MLR in forecasting the 1, 3, 6 and 12 months\n",
    "SPEI.'''\n",
    "a[9] = '''Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever\n",
    "large labeled training sets are available, they cannot be used to map sequences to\n",
    "sequences. In this paper, we present a general end-to-end approach to sequence\n",
    "learning that makes minimal assumptions on the sequence structure. Our method\n",
    "uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence\n",
    "to a vector of a fixed dimensionality, and then another deep LSTM to decode the\n",
    "target sequence from the vector. Our main result is that on an English to French\n",
    "translation task from the WMT-14 dataset, the translations produced by the LSTM\n",
    "achieve a BLEU score of 34.8 on the entire test set, where the LSTM’s BLEU\n",
    "score was penalized on out-of-vocabulary words. Additionally, the LSTM did not\n",
    "have difficulty on long sentences. For comparison, a phrase-based SMT system\n",
    "achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM\n",
    "to rerank the 1000 hypotheses produced by the aforementioned SMT system, its\n",
    "BLEU score increases to 36.5, which is close to the previous state of the art. The\n",
    "LSTM also learned sensible phrase and sentence representations that are sensitive\n",
    "to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but\n",
    "not target sentences) improved the LSTM’s performance markedly, because doing\n",
    "so introduced many short term dependencies between the source and the target\n",
    "sentence which made the optimization problem easier.'''\n",
    "a[10] = '''In this work, we address the human parsing task with a\n",
    "novel Contextualized Convolutional Neural Network (CoCNN) architecture, which well integrates the cross-layer\n",
    "context, global image-level context, within-super-pixel context and cross-super-pixel neighborhood context into a unified network. Given an input human image, Co-CNN produces the pixel-wise categorization in an end-to-end way.\n",
    "First, the cross-layer context is captured by our basic localto-global-to-local structure, which hierarchically combines\n",
    "the global semantic information and the local fine details\n",
    "across different convolutional layers. Second, the global\n",
    "image-level label prediction is used as an auxiliary objective in the intermediate layer of the Co-CNN, and its outputs are further used for guiding the feature learning in subsequent convolutional layers to leverage the global imagelevel context. Finally, to further utilize the local super-pixel\n",
    "contexts, the within-super-pixel smoothing and cross-superpixel neighbourhood voting are formulated as natural subcomponents of the Co-CNN to achieve the local label consistency in both training and testing process. Comprehensive evaluations on two public datasets well demonstrate the\n",
    "significant superiority of our Co-CNN over other state-ofthe-arts for human parsing. In particular, the F-1 score on\n",
    "the large dataset [15] reaches 76.95% by Co-CNN, significantly higher than 62.81% and 64.38% by the state-of-theart algorithms, M-CNN [21] and ATR [15], respectively'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(a, columns=['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('summaries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ['']*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f[0] = ''''''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
